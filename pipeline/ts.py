import sys
import os
import pandas as pd
import numpy as np
import re
import sqlalchemy
import hashlib
from datetime import datetime, timedelta
from sqlalchemy import text

# ==============================================================================
# 1. C·∫§U H√åNH & IMPORT T·ª™ CONFIG
# ==============================================================================
# Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import ƒë∆∞·ª£c 'pipeline.config'
current_dir = os.getcwd()

project_root = os.path.abspath(os.path.join(current_dir, '..')) 
if project_root not in sys.path:
    sys.path.append(project_root)

# Th·ª≠ import DATABASE_URL t·ª´ file config c·ªßa b·∫°n
try:
    from pipeline.config import DATABASE_URL
    print("‚úÖ ƒê√£ l·∫•y Connection String t·ª´ pipeline/config.py th√†nh c√¥ng!")
except ImportError:
    # Fallback x·ª≠ l√Ω n·∫øu ch·∫°y tr·ª±c ti·∫øp t·∫°i root m√† kh√¥ng t√¨m th·∫•y module
    sys.path.append(current_dir)
    try:
        from pipeline.config import DATABASE_URL
        print("‚úÖ ƒê√£ l·∫•y Connection String t·ª´ pipeline/config.py (t·∫°i root) th√†nh c√¥ng!")
    except ImportError as e:
        print(f"L·ªói import config: {e}")
        print("Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n file config.py.")
        DATABASE_URL = None
    

   
# ==============================================================================
# 2. CLASS ETL (LOGIC 63 T·ªàNH -> 34 ƒê·∫¶U M·ªêI + T·ªåA ƒê·ªò CHI TI·∫æT)
# ==============================================================================
class RecruitmentETL:

    def __init__(self, connection_string):
        self.engine = sqlalchemy.create_engine(connection_string)
        print("‚úÖ ƒê√£ kh·ªüi t·∫°o c·∫•u h√¨nh & Logic Geo Mapping (Chi ti·∫øt -> G·ªôp).")
    
        self.merge_map = self._init_merge_mapping()
        self.coord_map = self._init_full_coords()
        self.industry_map = self._init_industry_map()
        #self.job_title_map = self._init_job_title_map()
        self.skill_map = self._init_skill_map()
        self.edu_map = self._init_education()

    # --------------------------------------------------------------------------
    # A. T·ª™ ƒêI·ªÇN LU·∫¨T G·ªòP (INPUT -> T·ªàNH ƒê√çCH)
    # --------------------------------------------------------------------------
    def __init__(self, *args, **kwargs):
        self.garbage_locations = {
            '10 n∆°i kh√°c', 
            'to√†n qu·ªëc', 
            't·ªânh kh√°c', 
            'nhi·ªÅu n∆°i',
            'vi·ªác l√†m kh√°c' # V√≠ d·ª• th√™m
        }
    def save_data_via_procedure(self, df, chunk_size=1000):
        """
        ƒê·∫©y d·ªØ li·ªáu v√†o SQL Server th√¥ng qua Stored Procedure sp_Import_FactCleanJobs_JSON
        """
        if df.empty:
            print("‚ö†Ô∏è DataFrame r·ªóng, kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u.")
            return
        df = df.where(pd.notnull(df), None)

        # ƒê·∫£m b·∫£o c√°c c·ªôt ng√†y th√°ng l√† string ho·∫∑c datetime object chu·∫©n
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                 # Format v·ªÅ YYYY-MM-DD ƒë·ªÉ SQL Server d·ªÖ nu·ªët
                 df[col] = df[col].astype(str).replace('NaT', None)

        total_rows = len(df)
        print(f"ƒêang ƒë·∫©y {total_rows} d√≤ng v√†o SQL Server (Upsert)...")

        # 2. M·ªü k·∫øt n·ªëi Transaction (t·ª± ƒë·ªông Commit/Rollback)
        try:
            with self.engine.begin() as conn: 
                for start in range(0, total_rows, chunk_size):
                    end = start + chunk_size
                    chunk = df.iloc[start:end]
                    
                    # 3. Convert DataFrame -> JSON String
                    # orient='records': T·∫°o list of dicts [{}, {}]
                    # date_format='iso': Chu·∫©n ng√†y th√°ng qu·ªëc t·∫ø
                    # force_ascii=False: Gi·ªØ nguy√™n ti·∫øng Vi·ªát c√≥ d·∫•u
                    json_data = chunk.to_json(orient='records', date_format='iso', force_ascii=False)
                    
                    try:
                        # 4. Th·ª±c thi Stored Procedure (SQL Server Syntax)
                        # L∆∞u √Ω: Ph·∫£i d√πng :json_param l√†m placeholder ƒë·ªÉ tr√°nh l·ªói SQL Injection v√† l·ªói k√Ω t·ª± ƒë·∫∑c bi·ªát
                        # Th√™m [dbo]. ƒë·ªÉ SQL Server kh√¥ng ph·∫£i ƒëo√°n m√≤
                        query = text("EXEC [dbo].[sp_Import_FactCleanJobs_JSON] @JsonData = :json_param")
                        
                        conn.execute(query, {"json_param": json_data})
                        
                        print(f"    Chunk {start} -> {min(end, total_rows)}: Th√†nh c√¥ng.")
                        
                    except Exception as e:
                        print(f"   L·ªói t·∫°i chunk {start}: {e}")
                        # Debug: In ra m·ªôt ph·∫ßn JSON ƒë·ªÉ ki·ªÉm tra l·ªói c√∫ ph√°p n·∫øu c√≥
                        print(f"   --> Sample Data g√¢y l·ªói: {json_data[:200]}...")
                        raise e 
            
            print("üéâ Ho√†n t·∫•t qu√° tr√¨nh Import d·ªØ li·ªáu!")
            
        except Exception as e:
            print(f"‚õî L·ªói nghi√™m tr·ªçng trong qu√° tr√¨nh l∆∞u DB: {e}")
            # Re-raise ƒë·ªÉ d·ª´ng ch∆∞∆°ng tr√¨nh n·∫øu c·∫ßn
            raise e
    def _find_experience_coalesced(self, row):
        """
        ∆Øu ti√™n l·∫•y t·ª´ c·ªôt YeuCauKinhNghiem, n·∫øu tr·ªëng th√¨ t√¨m ki·∫øm trong YeuCauUngVien.
        """
        # 1. Ki·ªÉm tra c·ªôt ch√≠nh (YeuCauKinhNghiem)
        raw_exp_primary = row.get('YeuCauKinhNghiem')
        min_val, max_val = self._extract_experience_numerics(raw_exp_primary)

        # 2. Coalesce/Fallback: N·∫øu c·ªôt ch√≠nh kh√¥ng t√¨m th·∫•y s·ªë n√†o (tr·∫£ v·ªÅ None, None)
        if pd.isna(min_val) and pd.isna(max_val):
            # Th·ª≠ t√¨m ki·∫øm trong c·ªôt ph·ª• (YeuCauUngVien)
            raw_exp_secondary = row.get('YeuCauUngVien')
            min_val, max_val = self._extract_experience_numerics(raw_exp_secondary)

        # 3. ƒê·∫£m b·∫£o tr·∫£ v·ªÅ NaN n·∫øu kh√¥ng t√¨m th·∫•y g√¨ (ƒë·ªÉ logic Imputation sau x·ª≠ l√Ω)
        if pd.isna(min_val) and pd.isna(max_val):
            return pd.Series([np.nan, np.nan]) 

        return pd.Series([min_val, max_val])
    def _init_education(self):
        return {
            'Ti·∫øn sƒ©': ['ti·∫øn sƒ©', 'doctorate', 'phd'],
            'Th·∫°c sƒ©': ['th·∫°c sƒ©', 'master'],
            'ƒê·∫°i h·ªçc': ['ƒë·∫°i h·ªçc', 'c·ª≠ nh√¢n', 'k·ªπ s∆∞', 'bachelor', 'university'],
            'Cao ƒë·∫≥ng': ['cao ƒë·∫≥ng', 'college'],
            'Trung c·∫•p': ['trung c·∫•p', 'intermediate'],
            'T·ªët nghi·ªáp ph·ªï th√¥ng': ['t·ªët nghi·ªáp thpt', 'c·∫•p 3', 'high school', '12/12']
        }

    def _init_merge_mapping(self):
        """T·ª´ ƒëi·ªÉn: T√™n t√¨m th·∫•y trong JD -> T√™n T·ªânh G·ªôp (34 T·ªânh)"""
        return {
            # --- Nh√≥m 1: Mi·ªÅn T√¢y & Nam B·ªô ---
            "ki√™n giang": "An Giang", "an giang": "An Giang",
            "b·∫°c li√™u": "C√† Mau", "c√† mau": "C√† Mau",
            "b√¨nh ph∆∞·ªõc": "ƒê·ªìng Nai", "ƒë·ªìng nai": "ƒê·ªìng Nai",
            "ti·ªÅn giang": "ƒê·ªìng Th√°p", "ƒë·ªìng th√°p": "ƒê·ªìng Th√°p",
            "long an": "T√¢y Ninh", "t√¢y ninh": "T√¢y Ninh",
            "b·∫øn tre": "Vƒ©nh Long", "tr√† vinh": "Vƒ©nh Long", "vƒ©nh long": "Vƒ©nh Long",
            "s√≥c trƒÉng": "TP. C·∫ßn Th∆°", "h·∫≠u giang": "TP. C·∫ßn Th∆°", "c·∫ßn th∆°": "TP. C·∫ßn Th∆°", 
            "tp. c·∫ßn th∆°": "TP. C·∫ßn Th∆°", "tp c·∫ßn th∆°": "TP. C·∫ßn Th∆°",

            # --- Nh√≥m 2: Mi·ªÅn Trung & T√¢y Nguy√™n ---
            "ph√∫ y√™n": "ƒê·∫Øk L·∫Øk", "ƒë·∫Øk l·∫Øk": "ƒê·∫Øk L·∫Øk", "dak lak": "ƒê·∫Øk L·∫Øk",
            "b√¨nh ƒë·ªãnh": "Gia Lai", "gia lai": "Gia Lai",
            "ninh thu·∫≠n": "Kh√°nh Ho√†", "kh√°nh ho√†": "Kh√°nh Ho√†", "kh√°nh h√≤a": "Kh√°nh Ho√†", "nha trang": "Kh√°nh Ho√†",
            "ƒë·∫Øk n√¥ng": "L√¢m ƒê·ªìng", "dak nong": "L√¢m ƒê·ªìng", "b√¨nh thu·∫≠n": "L√¢m ƒê·ªìng", "l√¢m ƒë·ªìng": "L√¢m ƒê·ªìng", "ƒë√† l·∫°t": "L√¢m ƒê·ªìng",
            "kon tum": "Qu·∫£ng Ng√£i", "qu·∫£ng ng√£i": "Qu·∫£ng Ng√£i",
            "qu·∫£ng b√¨nh": "Qu·∫£ng Tr·ªã", "qu·∫£ng tr·ªã": "Qu·∫£ng Tr·ªã",
            "qu·∫£ng nam": "TP. ƒê√† N·∫µng", "ƒë√† n·∫µng": "TP. ƒê√† N·∫µng", "tp. ƒë√† n·∫µng": "TP. ƒê√† N·∫µng", "tp ƒë√† n·∫µng": "TP. ƒê√† N·∫µng",
            "th·ª´a thi√™n hu·∫ø": "TP. Hu·∫ø", "hu·∫ø": "TP. Hu·∫ø", "tp. hu·∫ø": "TP. Hu·∫ø", "tp hu·∫ø": "TP. Hu·∫ø",

            # --- Nh√≥m 3: Mi·ªÅn B·∫Øc ---
            "b·∫Øc giang": "B·∫Øc Ninh", "b·∫Øc ninh": "B·∫Øc Ninh",
            "th√°i b√¨nh": "H∆∞ng Y√™n", "h∆∞ng y√™n": "H∆∞ng Y√™n",
            "y√™n b√°i": "L√†o Cai", "l√†o cai": "L√†o Cai",
            "h√† nam": "Ninh B√¨nh", "nam ƒë·ªãnh": "Ninh B√¨nh", "ninh b√¨nh": "Ninh B√¨nh",
            "h√≤a b√¨nh": "Ph√∫ Th·ªç", "vƒ©nh ph√∫c": "Ph√∫ Th·ªç", "ph√∫ th·ªç": "Ph√∫ Th·ªç",
            "b·∫Øc k·∫°n": "Th√°i Nguy√™n", "b·∫Øc c·∫°n": "Th√°i Nguy√™n", "th√°i nguy√™n": "Th√°i Nguy√™n",
            "h√† giang": "Tuy√™n Quang", "tuy√™n quang": "Tuy√™n Quang",
            "h·∫£i d∆∞∆°ng": "TP. H·∫£i Ph√≤ng", "h·∫£i ph√≤ng": "TP. H·∫£i Ph√≤ng", "tp. h·∫£i ph√≤ng": "TP. H·∫£i Ph√≤ng",
            "h√† n·ªôi": "TP. H√† N·ªôi", "hn": "TP. H√† N·ªôi", "tp. h√† n·ªôi": "TP. H√† N·ªôi", "tp h√† n·ªôi": "TP. H√† N·ªôi",

            # --- Nh√≥m 4: TP. HCM ---
            "b√¨nh d∆∞∆°ng": "TP. H·ªì Ch√≠ Minh", "b√† r·ªãa": "TP. H·ªì Ch√≠ Minh", "v≈©ng t√†u": "TP. H·ªì Ch√≠ Minh",
            "b√† r·ªãa - v≈©ng t√†u": "TP. H·ªì Ch√≠ Minh", "h·ªì ch√≠ minh": "TP. H·ªì Ch√≠ Minh", "hcm": "TP. H·ªì Ch√≠ Minh",
            "tphcm": "TP. H·ªì Ch√≠ Minh", "sg": "TP. H·ªì Ch√≠ Minh", "s√†i g√≤n": "TP. H·ªì Ch√≠ Minh", "tp. h·ªì ch√≠ minh": "TP. H·ªì Ch√≠ Minh",

            # --- Nh√≥m 5: C√°c t·ªânh gi·ªØ nguy√™n ---
            "cao b·∫±ng": "Cao B·∫±ng", "ƒëi·ªán bi√™n": "ƒêi·ªán Bi√™n", "h√† tƒ©nh": "H√† Tƒ©nh",
            "lai ch√¢u": "Lai Ch√¢u", "l·∫°ng s∆°n": "L·∫°ng S∆°n", "ngh·ªá an": "Ngh·ªá An",
            "qu·∫£ng ninh": "Qu·∫£ng Ninh", "s∆°n la": "S∆°n La", "thanh h√≥a": "Thanh H√≥a"
        }
    def _init_full_coords(self):
        """T·ª´ ƒëi·ªÉn t·ªça ƒë·ªô G·ªêC (Full 63 T·ªânh)"""
        # Format: "key": ("Khu V·ª±c", Lat, Long, "T√™n G·ªëc Hi·ªÉn Th·ªã")
        return {
            "h√† n·ªôi": ("B·∫Øc", 21.0285, 105.8542, "TP. H√† N·ªôi"), "hn": ("B·∫Øc", 21.0285, 105.8542, "TP. H√† N·ªôi"),
            "b·∫Øc giang": ("B·∫Øc", 21.2731, 106.1946, "B·∫Øc Giang"), # T·ªça ƒë·ªô ri√™ng
            "b·∫Øc ninh": ("B·∫Øc", 21.1861, 106.0763, "B·∫Øc Ninh"),
            "h·∫£i d∆∞∆°ng": ("B·∫Øc", 20.9409, 106.3330, "H·∫£i D∆∞∆°ng"), 
            "h∆∞ng y√™n": ("B·∫Øc", 20.9333, 106.3167, "H∆∞ng Y√™n"),
            "h·∫£i ph√≤ng": ("B·∫Øc", 20.8449, 106.6881, "TP. H·∫£i Ph√≤ng"),
            "vƒ©nh ph√∫c": ("B·∫Øc", 21.3093, 105.6053, "Vƒ©nh Ph√∫c"), 
            "th√°i nguy√™n": ("B·∫Øc", 21.5672, 105.8244, "Th√°i Nguy√™n"),
            "th√°i b√¨nh": ("B·∫Øc", 20.4475, 106.3364, "Th√°i B√¨nh"),
            "nam ƒë·ªãnh": ("B·∫Øc", 20.4200, 106.1683, "Nam ƒê·ªãnh"), 
            "ninh b√¨nh": ("B·∫Øc", 20.2541, 105.9751, "Ninh B√¨nh"),
            "h√† nam": ("B·∫Øc", 20.5453, 105.9122, "H√† Nam"),
            "ph√∫ th·ªç": ("B·∫Øc", 21.3220, 105.2280, "Ph√∫ Th·ªç"), 
            "h√≤a b√¨nh": ("B·∫Øc", 20.8172, 105.3377, "H√≤a B√¨nh"),
            "b·∫Øc k·∫°n": ("B·∫Øc", 22.1472, 105.8364, "B·∫Øc K·∫°n"),
            "tuy√™n quang": ("B·∫Øc", 21.8251, 105.2155, "Tuy√™n Quang"),
            "l√†o cai": ("B·∫Øc", 22.4851, 103.9707, "L√†o Cai"), 
            "y√™n b√°i": ("B·∫Øc", 21.7229, 104.9113, "Y√™n B√°i"),
            "l·∫°ng s∆°n": ("B·∫Øc", 21.8538, 106.7607, "L·∫°ng S∆°n"), 
            "cao b·∫±ng": ("B·∫Øc", 22.6667, 106.2500, "Cao B·∫±ng"),
            "h√† giang": ("B·∫Øc", 22.8233, 104.9839, "H√† Giang"), 
            "s∆°n la": ("B·∫Øc", 21.3283, 103.9015, "S∆°n La"),
            "lai ch√¢u": ("B·∫Øc", 22.4014, 103.2736, "Lai Ch√¢u"), 
            "ƒëi·ªán bi√™n": ("B·∫Øc", 21.3850, 103.0210, "ƒêi·ªán Bi√™n"),
            "qu·∫£ng ninh": ("B·∫Øc", 20.9500, 107.0833, "Qu·∫£ng Ninh"),

            # Mi·ªÅn Trung
            "thanh h√≥a": ("Trung", 19.8077, 105.7765, "Thanh H√≥a"), "ngh·ªá an": ("Trung", 18.6734, 105.6791, "Ngh·ªá An"),
            "h√† tƒ©nh": ("Trung", 18.3427, 105.9058, "H√† Tƒ©nh"), "qu·∫£ng b√¨nh": ("Trung", 17.4833, 106.6000, "Qu·∫£ng B√¨nh"),
            "qu·∫£ng tr·ªã": ("Trung", 16.7423, 107.1856, "Qu·∫£ng Tr·ªã"), "hu·∫ø": ("Trung", 16.4637, 107.5909, "TP. Hu·∫ø"),
            "ƒë√† n·∫µng": ("Trung", 16.0544, 108.2022, "TP. ƒê√† N·∫µng"), "qu·∫£ng nam": ("Trung", 15.5804, 108.4816, "Qu·∫£ng Nam"),
            "qu·∫£ng ng√£i": ("Trung", 15.1205, 108.7923, "Qu·∫£ng Ng√£i"), "b√¨nh ƒë·ªãnh": ("Trung", 13.7830, 109.2197, "B√¨nh ƒê·ªãnh"),
            "ph√∫ y√™n": ("Trung", 13.0882, 109.0913, "Ph√∫ Y√™n"), "kh√°nh h√≤a": ("Trung", 12.2388, 109.1967, "Kh√°nh Ho√†"),
            "ninh thu·∫≠n": ("Trung", 11.5647, 108.9902, "Ninh Thu·∫≠n"), "b√¨nh thu·∫≠n": ("Trung", 10.9333, 108.1000, "B√¨nh Thu·∫≠n"),
            "kon tum": ("Trung", 14.3500, 108.0000, "Kon Tum"), "gia lai": ("Trung", 13.9833, 108.0000, "Gia Lai"),
            "ƒë·∫Øk l·∫Øk": ("Trung", 12.6667, 108.0500, "ƒê·∫Øk L·∫Øk"), "ƒë·∫Øk n√¥ng": ("Trung", 12.0000, 107.6833, "ƒê·∫Øk N√¥ng"),
            "l√¢m ƒë·ªìng": ("Trung", 11.9404, 108.4583, "L√¢m ƒê·ªìng"),

            # Mi·ªÅn Nam
            "hcm": ("Nam", 10.8231, 106.6297, "TP. H·ªì Ch√≠ Minh"), "h·ªì ch√≠ minh": ("Nam", 10.8231, 106.6297, "TP. H·ªì Ch√≠ Minh"),
            "b√¨nh d∆∞∆°ng": ("Nam", 10.9805, 106.6576, "B√¨nh D∆∞∆°ng"), "ƒë·ªìng nai": ("Nam", 10.9574, 106.8427, "ƒê·ªìng Nai"),
            "b√† r·ªãa": ("Nam", 10.3460, 107.0843, "B√† R·ªãa - V≈©ng T√†u"), "v≈©ng t√†u": ("Nam", 10.3460, 107.0843, "B√† R·ªãa - V≈©ng T√†u"),
            "t√¢y ninh": ("Nam", 11.3667, 106.1167, "T√¢y Ninh"), "b√¨nh ph∆∞·ªõc": ("Nam", 11.5333, 106.9000, "B√¨nh Ph∆∞·ªõc"),
            "long an": ("Nam", 10.5333, 106.4000, "Long An"), "ti·ªÅn giang": ("Nam", 10.3592, 106.3653, "Ti·ªÅn Giang"),
            "b·∫øn tre": ("Nam", 10.2373, 106.3752, "B·∫øn Tre"), "tr√† vinh": ("Nam", 9.9372, 106.3421, "Tr√† Vinh"),
            "vƒ©nh long": ("Nam", 10.2541, 105.9723, "Vƒ©nh Long"), "ƒë·ªìng th√°p": ("Nam", 10.4564, 105.6425, "ƒê·ªìng Th√°p"),
            "an giang": ("Nam", 10.3759, 105.4185, "An Giang"), "c·∫ßn th∆°": ("Nam", 10.0452, 105.7469, "TP. C·∫ßn Th∆°"),
            "h·∫≠u giang": ("Nam", 9.7842, 105.4700, "H·∫≠u Giang"), "s√≥c trƒÉng": ("Nam", 9.6033, 105.9722, "S√≥c TrƒÉng"),
            "ki√™n giang": ("Nam", 10.0076, 105.0869, "Ki√™n Giang"), "b·∫°c li√™u": ("Nam", 9.2922, 105.7249, "B·∫°c Li√™u"),
            "c√† mau": ("Nam", 9.1755, 105.1522, "C√† Mau")
        } 
    def _init_skill_map(self):
        return {
            "hard": {
        # --- Ng√¥n ng·ªØ l·∫≠p tr√¨nh ---
        "Python": ["python"],
        "Java": ["java ", "java,"], 
        "Go/Golang": ["golang", "go lang"], 
        "JavaScript": ["javascript", "js ", "js,", "js."],
        "TypeScript": ["typescript", "ts"],
        "C++": ["c\+\+"], 
        "C#": ["c#", ".net", "dotnet"],
        "PHP": ["php"],
        "Ruby": ["ruby", "rails"],
        "Swift": ["swift"],
        "Kotlin": ["kotlin"],
        "Dart": ["dart", "flutter"], 
        "R": ["r lang", "r programming"], 
        "SQL": ["sql", "mysql", "postgres", "sql server", "nosql", "mongodb", "redis"], # G·ªôp DB v√†o ƒë√¢y
        "HTML/CSS": ["html", "css"],
        "Rust": ["rust"],
        "Scala": ["scala"],
        "Bash/Shell": ["bash", "shell script", "linux"],
        "PowerShell": ["powershell"],
        "VBA": ["vba", "excel macro"],
        "MATLAB": ["matlab"],
        "Assembly": ["assembly", "asm"],
        
        # --- Framework/Lib ---
        "React": ["react", "reactjs", "react.js", "react native"],
        "Angular": ["angular"],
        "Vue": ["vue", "vuejs"],
        "NodeJS": ["node", "nodejs", "node.js"],
        "Spring": ["spring boot", "spring mvc"],
        "Django/Flask": ["django", "flask"],
        
        # --- Cloud & DevOps (ƒê√£ g·ªôp tr√πng) ---
        "AWS": ["aws", "amazon web services"],
        "Azure": ["azure"],
        "GCP": ["gcp", "google cloud"],
        "Docker": ["docker"],
        "Kubernetes": ["k8s", "kubernetes"],
        "Git": ["git", "github", "gitlab", "svn"],
        
        # --- Data Visualization & Analytics ---
        "Excel": ["excel", "spreadsheet", "google sheet", "google sheets", "vlookup", "pivot table"],
        "Power BI": ["power bi", "powerbi", "dax", "power query"],
        "Tableau": ["tableau"],
        "Looker": ["looker", "google data studio"],
        "Qlik": ["qlik", "qlikview", "qliksense"],
        "SAS/SPSS": ["sas", "spss"],
        
        # --- C√¥ng c·ª• Qu·∫£n l√Ω & Design ---
        "Jira/Confluence": ["jira", "confluence", "atlassian"],
        "Trello/Asana": ["trello", "asana", "monday.com"],
        "Office/Tin h·ªçc": ["word", "powerpoint", "ms office", "tin h·ªçc vƒÉn ph√≤ng"],
        "Design Tool": ["figma", "photoshop", "adobe xd", "sketch"]
    }
,
            "soft": {
        # --- Giao ti·∫øp & L√£nh ƒë·∫°o ---
        "Giao ti·∫øp": ["giao ti·∫øp", "communication", "tr√¨nh b√†y", "thuy·∫øt tr√¨nh", "presentation"],
        "L√£nh ƒë·∫°o": ["l√£nh ƒë·∫°o", "leadership", "d·∫´n d·∫Øt", "qu·∫£n l√Ω nh√≥m", "team lead"],
        "Th∆∞∆°ng l∆∞·ª£ng": ["th∆∞∆°ng l∆∞·ª£ng", "ƒë√†m ph√°n", "negotiation"],
        
        # --- T∆∞ duy ---
        "Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ": ["gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ", "problem solving", "x·ª≠ l√Ω t√¨nh hu·ªëng"],
        "T∆∞ duy ph·∫£n bi·ªán": ["ph·∫£n bi·ªán", "critical thinking", "t∆∞ duy logic"],
        "S√°ng t·∫°o": ["s√°ng t·∫°o", "creative", "innovation"],
        
        # --- Th√°i ƒë·ªô ---
        "Qu·∫£n l√Ω th·ªùi gian": ["qu·∫£n l√Ω th·ªùi gian", "time management", "s·∫Øp x·∫øp c√¥ng vi·ªác"],
        "L√†m vi·ªác nh√≥m": ["l√†m vi·ªác nh√≥m", "teamwork", "team work", "h√≤a ƒë·ªìng"],
        "Ch·ªãu √°p l·ª±c": ["ch·ªãu ƒë∆∞·ª£c √°p l·ª±c", "work under pressure", "√°p l·ª±c cao"],
        "T·ª± h·ªçc": ["t·ª± h·ªçc", "self-learning", "th√≠ch nghi", "ham h·ªçc h·ªèi"],
        
        # --- Ngo·∫°i ng·ªØ ---
        "Ti·∫øng Anh": ["ti·∫øng anh", "english", "toeic", "ielts", "toefl"],
        "Ti·∫øng Nh·∫≠t": ["ti·∫øng nh·∫≠t", "japanese", "n1", "n2", "n3"],
        "Ti·∫øng Trung": ["ti·∫øng trung", "chinese", "hsk"],
        "Ti·∫øng H√†n": ["ti·∫øng h√†n", "korean", "topik"]
    }
        }
    def _init_industry_map(self):
        return {
            "T√†i ch√≠nh - Ng√¢n h√†ng": ["ƒë·∫ßu t∆∞","k·∫ø to√°n", "ki·ªÉm to√°n", "thu·∫ø","ng√¢n h√†ng", "ch·ª©ng kho√°n", "t√†i ch√≠nh", "b·∫£o hi·ªÉm", "audit"],
            "S·∫£n xu·∫•t & K·ªπ thu·∫≠t": [ "s·∫£n xu·∫•t", "v·∫≠n h√†nh s·∫£n xu·∫•t", "c∆° kh√≠", "√¥ t√¥", "t·ª± ƒë·ªông h√≥a", 
        "ƒëi·ªán / ƒëi·ªán t·ª≠", "ƒëi·ªán l·∫°nh", "ƒëi·ªán c√¥ng nghi·ªáp", "b·∫£o tr√¨", "s·ª≠a ch·ªØa",
        "d·ªát may", "da gi√†y", "th·ªùi trang", "g·ªó", "n·ªôi th·∫•t", 
        "d·∫ßu kh√≠", "kho√°ng s·∫£n", "nƒÉng l∆∞·ª£ng", "h√≥a h·ªçc", "c√¥ng nghi·ªáp",
        "n√¥ng nghi·ªáp", "n√¥ng l√¢m ng∆∞ nghi·ªáp", "k·ªπ thu·∫≠t ·ª©ng d·ª•ng", "qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng", "qa/qc", "khu c√¥ng nghi·ªáp"],
            "Th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ & B√°n l·∫ª": ["b√°n l·∫ª", "b√°n s·ªâ", "h√†ng ti√™u d√πng", "fmcg", "th·ª±c ph·∫©m", "ƒë·ªì u·ªëng", 
        "h√†ng gia d·ª•ng", "chƒÉm s√≥c c√° nh√¢n", "th∆∞∆°ng m·∫°i t·ªïng h·ª£p", "si√™u th·ªã",
        "th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠", "e-commerce","retail"],
            "Y t·∫ø & S·ª©c kh·ªèe": ["y t·∫ø", "d∆∞·ª£c", "b·ªánh vi·ªán", "chƒÉm s√≥c s·ª©c kh·ªèe", "th·∫©m m·ªπ", "l√†m ƒë·∫πp", 
        "c√¥ng ngh·ªá sinh h·ªçc", "h√≥a m·ªπ ph·∫©m", "nha khoa", "healthcare", "pharma"],
            "X√¢y d·ª±ng & B·∫•t ƒë·ªông s·∫£n": ["real estate","x√¢y d·ª±ng", "b·∫•t ƒë·ªông s·∫£n", "ki·∫øn tr√∫c", "thi·∫øt k·∫ø n·ªôi th·∫•t", "v·∫≠t li·ªáu x√¢y d·ª±ng"],
                "V·∫≠n t·∫£i & Logistics": [
        "v·∫≠n chuy·ªÉn", "giao nh·∫≠n", "kho v·∫≠n", "logistics", "kho b√£i", "h√†ng kh√¥ng", 
        "xu·∫•t nh·∫≠p kh·∫©u", "thu mua", "v·∫≠t t∆∞", "chu·ªói cung ·ª©ng"
    ],

    
    "D·ªãch v·ª• & Gi·∫£i tr√≠": [
        "du l·ªãch", "nh√† h√†ng", "kh√°ch s·∫°n", "ngh·ªá thu·∫≠t", "thi·∫øt k·∫ø", "gi·∫£i tr√≠", 
        "truy·ªÅn h√¨nh", "b√°o ch√≠", "bi√™n t·∫≠p", "xu·∫•t b·∫£n", "in ·∫•n", "t·ªï ch·ª©c s·ª± ki·ªán"
    ],

    
    "Gi√°o d·ª•c & ƒê√†o t·∫°o": [
        "gi√°o d·ª•c", "ƒë√†o t·∫°o", "th∆∞ vi·ªán", "tr∆∞·ªùng h·ªçc", "trung t√¢m anh ng·ªØ"
    ],

    
    "Marketing & Truy·ªÅn th√¥ng": [
        "marketing", "ti·∫øp th·ªã", "qu·∫£ng c√°o", "truy·ªÅn th√¥ng", "ƒë·ªëi ngo·∫°i", 
        "pr", "agency", "digital marketing"
    ],

    
    "D·ªãch v·ª• doanh nghi·ªáp": [
        "nh√¢n s·ª±", "h√†nh ch√≠nh", "th∆∞ k√Ω", "lu·∫≠t", "ph√°p l√Ω", 
        "bi√™n phi√™n d·ªãch", "th√¥ng d·ªãch", "t∆∞ v·∫•n", "d·ªãch v·ª• kh√°ch h√†ng"
    ],
    
    
    "C√¥ng ngh·ªá & Vi·ªÖn th√¥ng": [
        "cntt", "ph·∫ßn m·ªÅm", "ph·∫ßn c·ª©ng", "m·∫°ng", "vi·ªÖn th√¥ng", "b∆∞u ch√≠nh vi·ªÖn th√¥ng",
        "internet", "online", "game", "it - ph·∫ßn m·ªÅm", "it - ph·∫ßn c·ª©ng"
    ],
    
    
    "Kinh doanh / Sales": [
        "b√°n h√†ng", "kinh doanh", "sales", "ph√°t tri·ªÉn th·ªã tr∆∞·ªùng"
    ]

        }

    # ==========================================================================
    # C. C√ÅC H√ÄM X·ª¨ L√ù (TRANSFORMATION)
    # ==========================================================================
    def process_interest_text(self, text):
        """
        H√†m ch√≠nh: Nh·∫≠n v√†o text (v√≠ d·ª• c·ªôt Salary ho·∫∑c Quy·ªÅn l·ª£i) -> Tr·∫£ v·ªÅ th√¥ng tin l∆∞∆°ng
        """
        # 1. Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh
        result = {
            "MucLuongMin": np.nan,
            "MucLuongMax": np.nan,
            "MucLuongTB": np.nan,
            "KhoangLuong": "Th·ªèa thu·∫≠n" # Label ph√¢n lo·∫°i
        }

        if not isinstance(text, str) or not text:
            return result

        text_lower = text.lower()

        # 2. Tr√≠ch xu·∫•t L∆∞∆°ng (Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ h√†m self.clean_salary tr·∫£ v·ªÅ Min/Max)
     
        salary_min, salary_max = self.clean_salary(text_lower)

        # 3. T√≠nh L∆∞∆°ng Trung B√¨nh (Logic x·ª≠ l√Ω Null)
        salary_tb = np.nan
        
        if pd.notna(salary_min) and pd.notna(salary_max):
            salary_tb = (salary_min + salary_max) / 2
        elif pd.notna(salary_min): # Ch·ªâ c√≥ min (VD: "T·ª´ 10 tri·ªáu")
            salary_tb = salary_min
        elif pd.notna(salary_max): # Ch·ªâ c√≥ max (VD: "L√™n ƒë·∫øn 20 tri·ªáu")
            salary_tb = salary_max

        # 4. G√°n gi√° tr·ªã t√≠nh to√°n v√†o k·∫øt qu·∫£
        result["MucLuongMin"] = salary_min
        result["MucLuongMax"] = salary_max
        result["MucLuongTB"] = salary_tb

        # 5. Ph√¢n lo·∫°i kho·∫£ng l∆∞∆°ng (Labeling)
        # G·ªçi h√†m ph·ª• ƒë√£ t√°ch ra ·ªü tr√™n
        result["KhoangLuong"] = self._get_salary_range_label(salary_tb)

        return result
    
    def process_requirements_text(self, text):
        """
        H√†m t·ªïng: Nh·∫≠n v√†o text 'Y√™u C·∫ßu ·ª®ng Vi√™n' -> Tr·∫£ v·ªÅ Dict c√°c th√¥ng tin tr√≠ch xu·∫•t
        """
        if not isinstance(text, str) or not text:
            # Tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu text r·ªóng
            return {
                "YeuCauKinhNghiemMin": np.nan,
                "YeuCauKinhNghiemMax": np.nan,
                "YeuCauKinhNghiemTB": np.nan,
                "PhanLoaiKinhNghiem": "Kh√¥ng y√™u c·∫ßu kinh nghi·ªám",
                "HardSkills": "Kh√¥ng y√™u c·∫ßu",
                "SoftSkills": "Kh√¥ng y√™u c·∫ßu",
                "HocVan_YeuCau": "Kh√°c",
                "CapBac_YeuCau": "Nh√¢n vi√™n", 
                "LinhVuc_YeuCau": "C√¥ng ngh·ªá & Vi·ªÖn th√¥ng"
            }
        
        text_lower = text.lower()

        # 1. Tr√≠ch xu·∫•t Kinh Nghi·ªám (S·ªë nƒÉm)
        exp_min, exp_max = self._extract_experience_numerics_strict(text_lower)
        # T√≠nh trung b√¨nh v√† ph√¢n lo·∫°i
        exp_tb = 0.0
        label = "Kh√¥ng y√™u c·∫ßu kinh nghi·ªám"
        
        if pd.notna(exp_max):
            exp_tb = (exp_min + exp_max) / 2 if pd.notna(exp_min) else exp_max
        elif pd.notna(exp_min):
            exp_tb = exp_min
        
        if exp_tb > 0:
            if exp_tb < 1: label = "D∆∞·ªõi 1 nƒÉm"
            elif exp_tb < 3: label = "1 ‚Äì 3 nƒÉm"
            elif exp_tb < 5: label = "3 ‚Äì 5 nƒÉm"
            else: label = "Tr√™n 5 nƒÉm"

        # 2. Tr√≠ch xu·∫•t K·ªπ nƒÉng (C·ª©ng/M·ªÅm)
        hard_skills = self._extract_hard_skills(text) 
        soft_skills = self._extract_soft_skills(text) 

        # 3. Tr√≠ch xu·∫•t H·ªçc v·∫•n
        hoc_van = self.clean_education(text_lower)

        # 4. Tr√≠ch xu·∫•t C·∫•p b·∫≠c (D·ª±a tr√™n y√™u c·∫ßu)
        cap_bac = self._extract_rank_strict(text_lower)
        #5, tr√≠ch xu·∫•t lƒ©nh v·ª±c
        linh_vuc = self.clean_industry(text_lower)

        return {
            "YeuCauKinhNghiemMin": exp_min,
            "YeuCauKinhNghiemMax": exp_max,
            "YeuCauKinhNghiemTB": exp_tb,
            "PhanLoaiKinhNghiem": label,
            "HardSkills": hard_skills,
            "SoftSkills": soft_skills,
            "HocVan_YeuCau": hoc_van,
            "CapBac_YeuCau": cap_bac,
            "LinhVuc_YeuCau":linh_vuc
        }



    def _extract_experience_numerics_strict(self, text):
        # Logic t√°ch s·ªë nƒÉm kinh nghi·ªám t·ª´ text
        if any(kw in text for kw in ['kh√¥ng y√™u c·∫ßu', 'no experience', 'ch∆∞a c√≥']): 
            return 0.0, 0.0
        
        matches = re.findall(r'(\d+(?:\.\d+)?)\s*(?:nƒÉm|year)', text)
        nums = [float(n) for n in matches]
        
        if not nums: return np.nan, np.nan
        
        # Logic min/max ƒë∆°n gi·∫£n
        if len(nums) == 1: 
            val = nums[0]
            if "tr√™n" in text or "h∆°n" in text: return val, np.nan
            if "d∆∞·ªõi" in text: return 0.0, val
            return val, val
        
        return min(nums), max(nums)

    def _extract_rank_strict(self, text):
        # T√¨m c·∫•p b·∫≠c y√™u c·∫ßu trong text (v√≠ d·ª•: "y√™u c·∫ßu tr√¨nh ƒë·ªô Senior")
        text = str(text).lower()
        if any(k in text for k in ['th·ª±c t·∫≠p', 'intern', 'trainee']): return "Th·ª±c t·∫≠p sinh"
        if any(k in text for k in ['ph√≥ gi√°m ƒë·ªëc', 'ph√≥ gƒë', 'vp ']): return "Ph√≥ gi√°m ƒë·ªëc"
        if any(k in text for k in ['gi√°m ƒë·ªëc', 'gƒë', 'director', 'ceo']): return "Gi√°m ƒë·ªëc"
        if any(k in text for k in ['tr∆∞·ªüng ph√≤ng', 'manager', 'lead', 'tr∆∞·ªüng nh√≥m']): return "Tr∆∞·ªüng ph√≤ng"
        return "Nh√¢n vi√™n"



    # ==========================================================================
    # NH√ìM 2: C√ÅC H√ÄM X·ª¨ L√ù TR∆Ø·ªúNG "M√î T·∫¢ C√îNG VI·ªÜC"
    # (Working Time, Work Mode, Employment Type)
    # ==========================================================================

    def process_description_text(self, text):
        """
        H√†m t·ªïng: Nh·∫≠n v√†o text 'M√¥ T·∫£ C√¥ng Vi·ªác' -> Tr·∫£ v·ªÅ Dict th√¥ng tin m√¥i tr∆∞·ªùng l√†m vi·ªác
        """
        if not isinstance(text, str) or not text:
            return {
                "KieuLamViec": "Onsite",
                "HinhThucLamViec_clean": "Full-time",
               
            }
        
        text_lower = text.lower()
        # 1. Ki·ªÉu l√†m vi·ªác (Remote/Hybrid)
        mode_work = self._determine_work_mode(text_lower) 

        # 2. H√¨nh th·ª©c (Full/Part)
        type_work = self._determine_employment_type(text_lower) 
        #3. S·ªë l∆∞·ª£ng tuy·ªÉn
        
        return {
            "KieuLamViec": mode_work,
            "HinhThucLamViec_clean": type_work,
        }
    # 1. H√†m quan tr·ªçng nh·∫•t: X·ª≠ l√Ω ƒê·ªãa ƒëi·ªÉm (G·ªôp T·ªânh + Gi·ªØ t·ªça ƒë·ªô g·ªëc)

    def clean_location_data(self, df):
        print("--- ƒêang x·ª≠ l√Ω Location (L·ªçc R√°c S·ªõm v√† Chuy·ªÉn v·ªÅ T·ªânh chu·∫©n) ---")

        # -------------------------------------------------------------
        # üéØ B∆Ø·ªöC 0: L·ªåC R√ÅC S·ªöM V√Ä CHU·∫®N B·ªä (NEW STEP)
        # -------------------------------------------------------------
        
        # Chu·∫©n h√≥a gi√° tr·ªã r√°c v·ªÅ ch·ªØ th∆∞·ªùng
        garbage_lower = [g.lower() for g in self.garbage_locations]
        # H√†m ki·ªÉm tra v√† thay th·∫ø gi√° tr·ªã r√°c b·∫±ng NaN (ƒë·ªÉ b·ªã lo·∫°i khi explode)
        def clean_raw_location(location):
            if not isinstance(location, str):
                return location
            
            loc_lower = location.lower().strip()
            
            # Ki·ªÉm tra kh·ªõp ch√≠nh x√°c ho·∫∑c kh·ªõp m·ªôt ph·∫ßn v·ªõi gi√° tr·ªã r√°c
            if loc_lower in garbage_lower or any(g in loc_lower for g in garbage_lower):
                return np.nan # Thay th·∫ø b·∫±ng NaN ƒë·ªÉ lo·∫°i b·ªè sau n√†y
            
            return location
            
        df['ViTri'] = df['ViTri'].apply(clean_raw_location)
        
        # 1. T√ÅCH D√íNG (Explode)
        # df.explode() s·∫Ω t·ª± ƒë·ªông lo·∫°i b·ªè c√°c gi√° tr·ªã NaN/None sau khi √°p d·ª•ng .apply() ·ªü tr√™n
        df['Temp_Loc_List'] = df['ViTri'].astype(str).apply(
            # ƒê·∫£m b·∫£o str('nan') c≈©ng ƒë∆∞·ª£c lo·∫°i tr·ª´
            lambda x: [i.strip() for i in re.split(r'[;,|&]|\s+-\s+', x) if i.strip() and i.strip().lower() != 'nan']
        )
        df_exploded = df.explode('Temp_Loc_List').dropna(subset=['Temp_Loc_List']) # Lo·∫°i b·ªè c√°c d√≤ng ch·ªâ ch·ª©a NaN
        
        # 2. H√ÄM MAPPING (ƒê·ªãnh nghƒ©a logic) - H√†m n√†y ƒë∆∞·ª£c ƒë∆°n gi·∫£n h√≥a v√¨ gi√° tr·ªã r√°c ƒë√£ b·ªã l·ªçc
        def get_geo_info(loc_raw):
            # [vi_tri_clean, tinh_thanh_chuan, region, lat, lng]
            
            # N·∫øu loc_raw l√† NaN (t·ª´ b∆∞·ªõc explode), h√£y b·ªè qua
            if pd.isna(loc_raw) or not isinstance(loc_raw, str):
                # C√°c gi√° tr·ªã r√°c ƒë√£ b·ªã l·ªçc, n√™n n·∫øu g·∫∑p non-string/NaN ·ªü ƒë√¢y th√¨ c√≥ th·ªÉ l√† d·ªØ li·ªáu r·ªóng.
                return ["Kh√°c", "Kh√°c", "Kh√°c", None, None]

            # [A] Chu·∫©n h√≥a Input
            loc_lower = loc_raw.lower().strip()
            loc_clean = re.sub(r'^(tp\.?|t\.|t·ªânh|th√†nh ph·ªë)\s+', '', loc_lower).strip()
            
            region, lat, lng = "Kh√°c", None, None
            tinh_thanh_chuan = "Kh√°c"
            
            # -------------------------------------------------------------
            # üéØ B∆Ø·ªöC B: T√¨m T·ªânh Chu·∫©n (Tinh_Thanh) b·∫±ng Merge Map
            # -------------------------------------------------------------
            
            # T√¨m kh·ªõp ch√≠nh x√°c
            if loc_clean in self.merge_map:
                tinh_thanh_chuan = self.merge_map[loc_clean]
            else:
                # T√¨m kh·ªõp m·ªôt ph·∫ßn (VD: 'ph∆∞·ªùng ƒë√¨nh b·∫£ng, b·∫Øc ninh' -> 'b·∫Øc ninh')
                for k, v in self.merge_map.items():
                    if k in loc_clean: 
                        tinh_thanh_chuan = v
                        break
            
            # -------------------------------------------------------------
            # üéØ B∆Ø·ªöC C: T√¨m T·ªça ƒê·ªô v√† X√ÅC ƒê·ªäNH ViTri_clean
            # -------------------------------------------------------------
            
            vi_tri_clean = tinh_thanh_chuan # M·∫∑c ƒë·ªãnh l√† t√™n t·ªânh ƒë√£ chu·∫©n h√≥a
            
            # 1. N·∫øu v·ªã tr√≠ c√≥ trong Coord Map (chi ti·∫øt v√† c√≥ t·ªça ƒë·ªô)
            if loc_clean in self.coord_map:
                info = self.coord_map[loc_clean]
                region, lat, lng, ten_chuan_coord = info[0], info[1], info[2], info[3]
                vi_tri_clean = ten_chuan_coord # G√°n l·∫°i ViTri_clean l√† t√™n chi ti·∫øt
                
            # 2. X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng t√¨m th·∫•y (tinh_thanh_chuan v·∫´n l√† "Kh√°c")
            if tinh_thanh_chuan == "Kh√°c":
                vi_tri_clean = "Kh√°c"
                
            # -------------------------------------------------------------
            
            return [vi_tri_clean, tinh_thanh_chuan, region, lat, lng]
            
        # 3. √ÅP D·ª§NG LOGIC V√ÄO DATAFRAME
        df_exploded['Temp_Geo_List'] = df_exploded['Temp_Loc_List'].apply(get_geo_info)
        
        # 4. T√ÅCH C·ªòT
        df_exploded['ViTri_clean'] = df_exploded['Temp_Geo_List'].apply(lambda x: x[0])
        df_exploded['Tinh_Thanh'] = df_exploded['Temp_Geo_List'].apply(lambda x: x[1])
        df_exploded['KhuVuc'] = df_exploded['Temp_Geo_List'].apply(lambda x: x[2])
        
        df_exploded['Latitude'] = df_exploded['Temp_Geo_List'].apply(lambda x: float(x[3]) if x[3] is not None else None).round(6)
        df_exploded['Longitude'] = df_exploded['Temp_Geo_List'].apply(lambda x: float(x[4]) if x[4] is not None else None).round(6)
        
        # X√≥a c·ªôt t·∫°m
        df_exploded.drop(columns=['Temp_Loc_List', 'Temp_Geo_List'], inplace=True)
        
        return df_exploded
    def clean_title(self, text):
        if not isinstance(text, str): 
            return None 
        
        # 1. Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ x·ª≠ l√Ω logic x√≥a t·ª´ r√°c
        text = str(text).lower()

        # --- DANH S√ÅCH T·ª™ R√ÅC (Gi·ªØ nguy√™n logic c·ªßa b·∫°n) ---
        noise_patterns = [
            r'tuy·ªÉn\s*g·∫•p', r'c·∫ßn\s*tuy·ªÉn', r'tuy·ªÉn\s*d·ª•ng', r'tuy·ªÉn', 
            r'urgent', r'hot', r'g·∫•p', r'ƒëi\s*l√†m\s*ngay',
            r'v·ªã\s*tr√≠',
            r's·ªë\s*l∆∞·ª£ng\s*\d+', r'\d+\s*slots?',
            r'l∆∞∆°ng\s*.*', 
            r'thu\s*nh·∫≠p.*',
            r'\d+\s*-\s*\d+\s*(tri·ªáu|tr|m|usd|\$)',
            r'upto\s*\d+',
            r'\d+\s*(nƒÉm|th√°ng)\s*k(?:inh)?\s*n(?:ghi·ªám)?', 
            r'k(?:inh)?\s*n(?:ghi·ªám)?\s*.*', 
            r'full\s*time', r'part\s*time', r'fulltime', r'parttime',
            r'remote', r'onsite', r'hybrid', r'wfh',
            r't·∫°i\s*vƒÉn\s*ph√≤ng', r'work\s*from\s*home'
        ]
        
        for pattern in noise_patterns:
            text = re.sub(pattern, ' ', text)

        # --- X√ìA ƒê·ªäA ƒêI·ªÇM (Gi·ªØ nguy√™n logic c·ªßa b·∫°n) ---
        if hasattr(self, 'location_map_values'):
            for loc in self.location_map_values:
                loc_clean = loc.lower().replace('.', r'\.')
                text = re.sub(r'(?:t·∫°i|·ªü|khu\s*v·ª±c|tp\.?)\s*' + re.escape(loc_clean) + r'\b', ' ', text)
                text = re.sub(r'\b' + re.escape(loc_clean) + r'\b', ' ', text)

        # --- CHU·∫®N H√ìA L·∫†I FORMAT (S·ª¨A ·ªû ƒê√ÇY) ---
        
        text = re.sub(r'[^\w\s\-\+#\./&]', ' ', text)
        
        # X√≥a kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\s+', ' ', text).strip()
        
        # X√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü ƒë·∫ßu cu·ªëi
        text = text.strip('.|,&-')

        if not text: 
            return None
        
        # Theo ·∫£nh m·∫´u output mong mu·ªën c·ªßa b·∫°n th√¨ c√≥ v·∫ª b·∫°n c·∫ßn .title()
        return text.title()
    def clean_salary(self, raw_salary):
        """
        H√†m chu·∫©n h√≥a l∆∞∆°ng: Tr·∫£ v·ªÅ [Min, Max]
        Input: "Up to 1000 USD", "10 - 20 Tri·ªáu", "Th·ªèa thu·∫≠n"
        Output: (0.0, 25000000.0)
        """
        # 1. X·ª≠ l√Ω null/r·ªóng
        if not isinstance(raw_salary, str) or not raw_salary: 
            return 0.0, 0.0 # Tr·∫£ v·ªÅ Tuple ho·∫∑c List
        
        text = raw_salary.lower()
        
        # 2. X√°c ƒë·ªãnh ƒê∆°n v·ªã (Unit) - S·ª≠a l·ªói logic if
        unit = 1
        if "usd" in text or "$" in text: 
            unit = 25000
        elif any(x in text for x in ["tri·ªáu", "tr", "millions", "m", "trieu"]): 
            unit = 1000000
        elif any(x in text for x in ["ngh√¨n", "k", "nghin"]): 
            unit = 1000
            
        # 3. L√†m s·∫°ch s·ªë (Gi·ªØ l·∫°i d·∫•u ch·∫•m th·∫≠p ph√¢n, x√≥a d·∫•u ph·∫©y h√†ng ngh√¨n)
        # V√≠ d·ª•: "1,000.5" -> "1000.5"
        text_clean = text.replace(',', '')
        
        # Regex b·∫Øt s·ªë th·ª±c (float)
        matches = re.findall(r'\d+(?:\.\d+)?', text_clean)
        try:
            nums = [float(n) for n in matches]
        except:
            return 0.0, 0.0
        
        if not nums: return 0.0, 0.0
        
        # 4. Logic ph√¢n chia Min/Max
        min_sal, max_sal = 0.0, 0.0
        
        if len(nums) == 1:
            val = nums[0] * unit
            # Logic ng·ªØ c·∫£nh
            if any(kw in text for kw in ["ƒë·∫øn", "t·ªõi", "up to", "d∆∞·ªõi", "max"]): 
                min_sal, max_sal = 0.0, val
            elif any(kw in text for kw in ["t·ª´", "tr√™n", "h∆°n", "min", "from"]): 
                min_sal, max_sal = val, 0.0 # 0.0 ·ªü max nghƒ©a l√† Open-ended (Kh√¥ng gi·ªõi h·∫°n)
            else: 
                # Tr∆∞·ªùng h·ª£p ch·ªâ ghi "1000$" -> Coi l√† l∆∞∆°ng c·ª©ng
                min_sal = max_sal = val
                
        elif len(nums) >= 2:
            # Tr∆∞·ªùng h·ª£p "10 - 20 tri·ªáu"
            v1 = nums[0] * unit
            v2 = nums[1] * unit
            # S·∫Øp x·∫øp l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o min lu√¥n nh·ªè h∆°n max
            min_sal, max_sal = min(v1, v2), max(v1, v2)

        return min_sal, max_sal
    def clean_deadline(self, row):
        try:
            # L·∫•y chu·ªói g·ªëc v√† ƒë∆∞a v·ªÅ ch·ªØ th∆∞·ªùng
            raw = str(row.get('HanNopHoSo', '')).lower().strip()
            # L·∫•y ng√†y c√†o d·ªØ li·ªáu l√†m m·ªëc (n·∫øu null th√¨ l·∫•y h√¥m nay)
            ref_date = pd.to_datetime(row.get('NgayCaoDuLieu', datetime.now()))
            
            # Case 1: B·∫Øt ƒë·ªãnh d·∫°ng "H·∫°n n·ªôp h·ªì s∆°: 30/04/2025"
            if "h·∫°n n·ªôp" in raw:
                m = re.search(r'(\d{1,2})[/-](\d{1,2})[/-](\d{4})', raw)
                if m: 
                    return datetime(int(m.group(3)), int(m.group(2)), int(m.group(1))).date()
            
            # Case 2: B·∫Øt ƒë·ªãnh d·∫°ng "C√≤n 20 ng√†y t·ªõi"
            if "ng√†y t·ªõi" in raw:
                m = re.search(r'(\d+)', raw)
                if m: 
                    return (ref_date + timedelta(days=int(m.group(1)))).date()
            
            # Case 3: Th·ª≠ parse tr·ª±c ti·∫øp (VD: "2025-04-30")
            parsed = pd.to_datetime(raw, dayfirst=True, errors='coerce')
            return parsed.date() if not pd.isna(parsed) else None
            
        except: 
            return "9999-12-31"

    def clean_experience(self, text):
        text = str(text).lower()
        if 'kh√¥ng' in text: return pd.Series([0.0, 0.0, 0.0])
        nums = [float(x) for x in re.findall(r'\d+(?:\.\d+)?', text)]
        if not nums: return pd.Series([None, None, None])
        mi, ma = (nums[0], nums[0]) if len(nums)==1 else (min(nums), max(nums))
        return pd.Series([mi, (mi+ma)/2, ma])

    # --- [2] H√ÄM M·ªöI: X·ª¨ L√ù KINH NGHI·ªÜM (Logic g·ªôp c·ªôt + Parse) ---
    def _parse_experience_to_list(self, row):
        # H√†m con ƒë·ªÉ parse text sang s·ªë
        def parse_text_exp(text):
            if not isinstance(text, str) or not text: return None
            t = text.lower().strip()
            if any(kw in t for kw in ['kh√¥ng y√™u c·∫ßu', 'no experience', 'ch∆∞a c√≥']): return [0.0, 0.0]
            nums = [float(n) for n in re.findall(r'\d+(?:\.\d+)?', t)]
            if not nums: return None
            if 'th√°ng' in t and 'nƒÉm' not in t: nums = [n / 12 for n in nums]
            
            mi, ma = None, None
            if 'd∆∞·ªõi 1 nƒÉm' in t: mi, ma = 0.0, 1.0
            elif any(kw in t for kw in ['tr√™n', 'h∆°n', 'over']): mi, ma = nums[0], None
            elif any(kw in t for kw in ['d∆∞·ªõi', 'less']): mi, ma = 0.0, nums[0]
            elif len(nums) >= 2: nums.sort(); mi, ma = nums[0], nums[-1]
            elif len(nums) == 1: mi, ma = nums[0], nums[0]
            return [mi, ma]

        # ∆Øu ti√™n c·ªôt ch√≠nh
        res = parse_text_exp(row.get('YeuCauKinhNghiem'))
        if res is not None: return res
        
        # Fallback sang c·ªôt ph·ª•
        res = parse_text_exp(row.get('YeuCauUngVien'))
        if res is not None: return res
        
        return [np.nan, np.nan]

    # --- [3] H√ÄM M·ªöI: X·ª¨ L√ù QUY M√î (Tr·∫£ v·ªÅ List thu·∫ßn) ---
    def _parse_size_to_list(self, text):
        if not isinstance(text, str) or not text: return [np.nan, np.nan]
        clean_text = text.lower().replace('.', '').replace(',', '')
        nums = [float(n) for n in re.findall(r'\d+', clean_text)]
        if not nums: return [np.nan, np.nan]
        
        if any(kw in clean_text for kw in ['d∆∞·ªõi', '√≠t h∆°n']): return [0.0, nums[0]]
        if any(kw in clean_text for kw in ['tr√™n', 'h∆°n']): return [nums[0], np.nan]
        if len(nums) >= 2: 
            nums.sort()
            return [nums[0], nums[-1]]
        return [nums[0], nums[0]]
    # --- H√ÄM PH·ª§ TR·ª¢ 2: PH√ÇN LO·∫†I KHO·∫¢NG L∆Ø∆†NG (BINNING) ---
    def _get_salary_range_label(self, avg_salary):
        if avg_salary == 0 or pd.isna(avg_salary): return "Th·ªèa thu·∫≠n"
        m = avg_salary / 1_000_000
        if m < 3: return "D∆∞·ªõi 3 tri·ªáu"
        elif 3 <= m < 10: return "3 - 10 tri·ªáu"
        elif 10 <= m < 15: return "10 - 15 tri·ªáu"
        elif 15 <= m < 25: return "15 - 25 tri·ªáu"
        elif 25 <= m < 35: return "25 - 35 tri·ªáu"
        elif 35 <= m < 50: return "35 - 50 tri·ªáu"
        else: return "H∆°n 50 tri·ªáu"
    # ==========================================================================
    # C√ÅC H√ÄM LOGIC PH·ª§ TR·ª¢ (HELPER METHODS) - C·∫¶N B·ªî SUNG
    # ==========================================================================
    # --- H√ÄM M·ªöI 1: X√ÅC ƒê·ªäNH H√åNH TH·ª®C (Full-time/Part-time) ---
    def _determine_employment_type(self, text):
        if not isinstance(text, str): return "Full-time"
        
        # Logic ∆∞u ti√™n t·ª´ kh√≥a
        kw_freelance = ['freelance', 'freelancer', 't·ª± do', 'c·ªông t√°c vi√™n', 'ctv', 'project base', 'theo d·ª± √°n', 'th·ªùi v·ª•']
        if any(k in text for k in kw_freelance):
            return "Freelance"
            
        kw_parttime = ['part time', 'part-time', 'b√°n th·ªùi gian', 'ca g√£y', '4 ti·∫øng', 'parttime']
        if any(k in text for k in kw_parttime):
            return "Part-time"
            
        # M·∫∑c ƒë·ªãnh l√† Full-time
        return "Full-time"

    # --- H√ÄM M·ªöI 2: X√ÅC ƒê·ªäNH KI·ªÇU L√ÄM VI·ªÜC (Onsite/Remote) ---
    def _determine_work_mode(self, text):
        if not isinstance(text, str): return "Onsite"
        
        kw_hybrid = [
            'hybrid', 'linh ho·∫°t', 'xen k·∫Ω', 'flexible', 'k·∫øt h·ª£p', 'mix', 
            'b√°n t·ª´ xa', 'semi-remote', 'ng√†y l√™n vƒÉn ph√≤ng', 'days at office'
        ]
        if any(k in text for k in kw_hybrid):
            return "Hybrid"
            
        kw_remote = ['remote', 't·ª´ xa', 'wfh', 'work from home', 't·∫°i nh√†', 'kh√¥ng c·∫ßn l√™n vƒÉn ph√≤ng']
        if any(k in text for k in kw_remote):
            return "Remote"
            
        # M·∫∑c ƒë·ªãnh l√† Onsite
        return "Onsite"
    
    # 2. X·ª≠ l√Ω C·∫•p b·∫≠c (Rank) - ƒê√¢y l√† h√†m b·∫°n ƒëang b·ªã thi·∫øu g√¢y l·ªói
    def clean_rank(self, text):
        t = str(text).lower()
        if any(x in t for x in ['th·ª±c t·∫≠p', 'intern', 'trainee']): return "Th·ª±c t·∫≠p sinh"
        if any(x in t for x in ['gi√°m ƒë·ªëc', 'director', 'ceo', 'c-level', 'head of']): return "Gi√°m ƒë·ªëc"
        if any(x in t for x in ['ph√≥ gi√°m ƒë·ªëc', 'vp ', 'vice president']): return "Ph√≥ gi√°m ƒë·ªëc"
        if any(x in t for x in ['tr∆∞·ªüng ph√≤ng', 'manager', 'lead', 'tr∆∞·ªüng nh√≥m', 'qu·∫£n l√Ω']): return "Tr∆∞·ªüng ph√≤ng"
        return "Nh√¢n vi√™n"

    # 3. X·ª≠ l√Ω Ng√†nh ngh·ªÅ (Industry)
    def clean_industry(self, text):
        text = str(text).lower()
        for cat, kws in self.industry_map.items():
            if any(k in text for k in kws): return cat
        return "C√¥ng ngh·ªá & Vi·ªÖn th√¥ng"

    # 4. X·ª≠ l√Ω S·ªë l∆∞·ª£ng tuy·ªÉn (Quantity) - ƒê√É C·∫¨P NH·∫¨T
    def clean_quantity(self, row):
        DEFAULT_QTY = 1
        qty_from_col = DEFAULT_QTY
        raw_col = str(row.get('SoLuongTuyen')) if pd.notna(row.get('SoLuongTuyen')) else ""
        raw_col_lower = raw_col.lower()
        kw_bulk = ['nhi·ªÅu', 's·ªë l∆∞·ª£ng l·ªõn', 'v√¥ h·∫°n', 'kh√¥ng gi·ªõi h·∫°n', 'h√†ng lo·∫°t']
        if any(k in raw_col_lower for k in kw_bulk):
            return 999 # G√°n s·ªë l∆∞·ª£ng l·ªõn c·ªë ƒë·ªãnh

        # T√¨m s·ªë trong c·ªôt SoLuong
        col_matches = re.findall(r'\d+', raw_col)
        if col_matches:
            # L·ªçc ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm nƒÉm, ch·ªâ l·∫•y s·ªë nh·ªè (< 1000)
            nums = [int(x) for x in col_matches if int(x) < 1000]
            if nums:
                qty_from_col = max(nums)

        # N·∫øu c·ªôt SoLuong ƒë√£ ghi r√µ r√†ng > 1, ta tin t∆∞·ªüng
        if qty_from_col > DEFAULT_QTY:
            return qty_from_col

        # ==========================================
        # B∆Ø·ªöC 2: X·ª¨ L√ù C·ªòT 'TenCongViec' (Fallback)
        # ==========================================
        title = str(row.get('CongViec')).lower() if pd.notna(row.get('CongViec')) else ""
        qty_from_title = DEFAULT_QTY

        # ƒê·ªãnh nghƒ©a c√°c m·∫´u c√¢u
        patterns = [
            r'tuy·ªÉn\s+(\d+)',           
            r'(\d+)\s+v·ªã tr√≠',           
            r'(\d+)\s+nh√¢n s·ª±',          
            r'(\d+)\s+nh√¢n vi√™n',        
            r'(\d+)\s+ng∆∞·ªùi',            
            r'(\d+)\s+b·∫°n',              
            r'(\d+)\s+slot',             
            r'(\d+)\s+k·ªπ s∆∞',
            r'(\d+)\s+chuy√™n vi√™n',
            r'(\d+)\s+k·ªπ thu·∫≠t vi√™n',
            r's·ªë l∆∞·ª£ng\s*[:\-]?\s*(\d+)'
        ]

        found_nums = []
        for pat in patterns:
            match = re.search(pat, title)
            if match:
                val = int(match.group(1))
                if DEFAULT_QTY < val < 200:
                    found_nums.append(val)

        if found_nums:
            qty_from_title = max(found_nums)

        # ==========================================
        # B∆Ø·ªöC 3: K·∫æT LU·∫¨N
        # ==========================================
        # Ch·ªçn gi√° tr·ªã cao nh·∫•t t·ª´ hai ngu·ªìn
        return max(qty_from_col, qty_from_title)

    # 5. X·ª≠ l√Ω H·ªçc v·∫•n (Education)
    def clean_education(self, text):
        if not isinstance(text, str):
            return "Kh√¥ng y√™u c·∫ßu"
        
        t = text.lower()
        
        # Duy·ªát qua Dictionary ƒë·ªÉ t√¨m t·ª´ kh√≥a
        # L∆∞u √Ω: Logic n√†y s·∫Ω tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë·∫ßu ti√™n t√¨m th·∫•y. 
        # V√≠ d·ª• d∆∞·ªõi ƒë√¢y ƒëang ∆∞u ti√™n theo th·ª© t·ª± trong Dict:
        for level, keywords in self.edu_map.items():
            if any(k in t for k in keywords):
                return level
                
        return "Kh√¥ng y√™u c·∫ßu"

    def find_education_coalesced(self, row):
        primary_edu = row.get('HocVan')
        secondary_req = row.get('YeuCauUngVien')

        # H√†m ph·ª• tr·ª£ ƒë·ªÉ ki·ªÉm tra chu·ªói h·ª£p l·ªá
        def is_valid_string(text):
            return pd.notna(text) and isinstance(text, str) and text.strip()

        # 1. Ki·ªÉm tra c·ªôt ch√≠nh (HocVan)
        # N·∫øu c·ªôt n√†y ƒë√£ chu·∫©n, ta l·∫•y lu√¥n. N·∫øu ch∆∞a chu·∫©n, b·∫°n c√≥ th·ªÉ g·ªçi self.clean_education(primary_edu)
        if is_valid_string(primary_edu):
            return primary_edu  # Ho·∫∑c: return self.clean_education(primary_edu)

        # 2. Ki·ªÉm tra c·ªôt ph·ª• (YeuCauUngVien)
        # QUAN TR·ªåNG: Ph·∫£i d√πng clean_education ƒë·ªÉ "b√≥c t√°ch" t·ª´ kh√≥a
        if is_valid_string(secondary_req):
            extracted_edu = self.clean_education(secondary_req)
            
            # Ch·ªâ tr·∫£ v·ªÅ n·∫øu t√¨m th·∫•y b·∫±ng c·∫•p (kh√°c "Kh√¥ng y√™u c·∫ßu")
            # N·∫øu clean_education tr·∫£ v·ªÅ "Kh√¥ng y√™u c·∫ßu", ta ƒë·ªÉ code ch·∫°y xu·ªëng d∆∞·ªõi
            if extracted_edu != "Kh√¥ng y√™u c·∫ßu":
                return extracted_edu

        # 3. M·∫∑c ƒë·ªãnh
        return "Kh√¥ng y√™u c·∫ßu"
    
    # 6. X·ª≠ l√Ω K·ªπ nƒÉng (Skills)
    def _extract_hard_skills(self, text):
        if not isinstance(text, str): return ""
        h = []
        # Qu√©t Hard Skills
        for k, keywords in self.skill_map.get('hard', {}).items():
            for kw in keywords:
                # D√πng regex boundary ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm t·ª´ con
                if re.search(r'(?:^|\W)(' + kw + r')(?:$|\W)', text):
                    h.append(k)
                    break 
        return ", ".join(sorted(h))

    # --- H√ÄM M·ªöI 2: T√ÅCH K·ª∏ NƒÇNG M·ªÄM (Soft Skills) ---
    def _extract_soft_skills(self, text):
        if not isinstance(text, str): return ""
        s = []
        # Qu√©t Soft Skills
        for k, keywords in self.skill_map.get('soft', {}).items():
            for kw in keywords:
                if re.search(r'(?:^|\W)(' + kw + r')(?:$|\W)', text):
                    s.append(k)
                    break
        return ", ".join(sorted(s))

    # 7. H√†m ph·ª•: Ph√¢n lo·∫°i kho·∫£ng l∆∞∆°ng (Labeling)
    def _get_salary_range_label(self, avg_salary):
        if avg_salary == 0 or pd.isna(avg_salary): return "Th·ªèa thu·∫≠n"
        m = avg_salary / 1_000_000
        if m < 3: return "D∆∞·ªõi 3 tri·ªáu"
        elif 3 <= m < 10: return "3 - 10 tri·ªáu"
        elif 10 <= m < 15: return "10 - 15 tri·ªáu"
        elif 15 <= m < 25: return "15 - 25 tri·ªáu"
        elif 25 <= m < 35: return "25 - 35 tri·ªáu"
        elif 35 <= m < 50: return "35 - 50 tri·ªáu"
        else: return "H∆°n 50 tri·ªáu"

    # 8. H√†m ph·ª•: Parse Kinh nghi·ªám (Numerics)
    def _extract_experience_numerics(self, raw_exp):
        if not isinstance(raw_exp, str) or not raw_exp: return pd.Series([None, None])
        text = raw_exp.lower().strip()
        if any(kw in text for kw in ['kh√¥ng y√™u c·∫ßu', 'no experience', 'ch∆∞a c√≥']): return pd.Series([0.0, 0.0])

        matches = re.findall(r'\d+(?:\.\d+)?', text)
        nums = [float(n) for n in matches]
        if not nums: return pd.Series([None, None])

        if 'th√°ng' in text and 'nƒÉm' not in text: nums = [n / 12 for n in nums]
        
        min_exp, max_exp = None, None
        if 'd∆∞·ªõi 1 nƒÉm' in text: min_exp, max_exp = 0.0, 1.0
        elif any(kw in text for kw in ['tr√™n', 'h∆°n', 'over']): min_exp, max_exp = nums[0], None
        elif any(kw in text for kw in ['d∆∞·ªõi', 'less']): min_exp, max_exp = 0.0, nums[0]
        elif len(nums) >= 2: nums.sort(); min_exp, max_exp = nums[0], nums[-1]
        elif len(nums) == 1: min_exp, max_exp = nums[0], nums[0]
        
        return pd.Series([min_exp, max_exp])

    # 9. H√†m ph·ª•: Parse Quy m√¥ (Numerics)
    def _extract_size_numerics(self, text):
        if not isinstance(text, str) or not text: return pd.Series([np.nan, np.nan])
        clean_text = text.lower().replace('.', '').replace(',', '')
        nums = [float(n) for n in re.findall(r'\d+', clean_text)]
        if not nums: return pd.Series([np.nan, np.nan])
        
        if any(kw in clean_text for kw in ['d∆∞·ªõi', '√≠t h∆°n']): return pd.Series([0.0, nums[0]])
        if any(kw in clean_text for kw in ['tr√™n', 'h∆°n']): return pd.Series([nums[0], np.nan])
        
        if len(nums) >= 2: 
            nums.sort()
            return pd.Series([nums[0], nums[-1]])
        return pd.Series([nums[0], nums[0]])
    def run(self):
        print("‚è≥ [1/7] T·∫£i d·ªØ li·ªáu t·ª´ Fact_JobPostings...")
        # Test limit
        df = pd.read_sql("SELECT*FROM fact_jobpostings limit 5;", self.engine)
        
        if df.empty:
            print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi.")
            return None
        
        print("‚è≥ [2/7] Chu·∫©n h√≥a Text c∆° b·∫£n & X·ª≠ l√Ω Ng√†y th√°ng...")
        
        # 1. Chu·∫©n h√≥a Text c∆° b·∫£n
        df['CongTy_clean'] = df['CongTy'].astype(str).str.strip().str.capitalize()
        df['CongViec_clean'] = df['CongViec'].apply(self.clean_title)
        
        # 2. X·ª≠ l√Ω Ng√†y th√°ng
        df['NgayCaoDuLieu'] = pd.to_datetime(df['NgayCaoDuLieu'], errors='coerce').dt.date
        df['HanNopHoSo_clean'] = df.apply(self.clean_deadline, axis=1)
        df['HanNopHoSo_clean'] = pd.to_datetime(df['HanNopHoSo_clean'], errors='coerce').dt.date

        print("‚è≥ [3/7] √Åp d·ª•ng Logic Tr√≠ch xu·∫•t (Feature Extraction)...")

        # --- A. X·ª¨ L√ù L∆Ø∆†NG ---
        print("   -> ƒêang x·ª≠ l√Ω L∆∞∆°ng...")
        # H√†m tr·∫£ v·ªÅ Dict, t√°ch th√†nh c·ªôt
        salary_info = df['MucLuong'].apply(self.process_interest_text).apply(pd.Series)
        df = pd.concat([df, salary_info], axis=1)

        # --- B. X·ª¨ L√ù Y√äU C·∫¶U ---
        print("   -> ƒêang x·ª≠ l√Ω Y√™u c·∫ßu (KN, K·ªπ nƒÉng, H·ªçc v·∫•n)...")
        df['Temp_Full_Req'] = df['YeuCauUngVien'].fillna('').astype(str) + " " + df['YeuCauKinhNghiem'].fillna('').astype(str)
        req_info = df['Temp_Full_Req'].apply(self.process_requirements_text).apply(pd.Series)
        
        # [FIX QUAN TR·ªåNG 1]: X√≥a c·ªôt tr√πng tr∆∞·ªõc khi concat
        cols_to_drop = [col for col in ['HocVan', 'LinhVuc_clean'] if col in req_info.columns]
        req_info = req_info.drop(columns=cols_to_drop)
        df = pd.concat([df, req_info], axis=1)
        
        # [Override Logic]
        df['HocVan_clean'] = df.apply(lambda row: self.find_education_coalesced(row) if pd.notna(row['HocVan']) else row['HocVan'], axis=1)
        df['LinhVuc_clean'] = df['LinhVuc'].apply(self.clean_industry)

        # --- C. X·ª¨ L√ù M√î T·∫¢ ---
        print("   -> ƒêang x·ª≠ l√Ω M√¥ t·∫£ (Working Mode, Type)...")
        # H√†m process_description_text (ƒë√£ s·ª≠a ·ªü B∆∞·ªõc 1) kh√¥ng c√≤n tr·∫£ v·ªÅ SoLuongTuyen n·ªØa
        desc_info = df['MoTaCongViec'].apply(self.process_description_text).apply(pd.Series)
        df = pd.concat([df, desc_info], axis=1)
        
        # [FIX QUAN TR·ªåNG 2]: G·ªçi clean_quantity ri√™ng bi·ªát, truy·ªÅn v√†o axis=1 (Row)
        print("   -> ƒêang t√≠nh to√°n S·ªë l∆∞·ª£ng tuy·ªÉn...")
        df['SoLuongTuyen_clean'] = df.apply(self.clean_quantity, axis=1)

        # --- D. X·ª¨ L√ù QUY M√î ---
        print("   -> ƒêang x·ª≠ l√Ω Quy m√¥ c√¥ng ty...")
        df['Temp_Size_List'] = df['QuyMoCongTy'].apply(self._parse_size_to_list)
        df['QuyMoCongTyMin_clean'] = df['Temp_Size_List'].apply(lambda x: x[0])
        df['QuyMoCongTyMax_clean'] = df['Temp_Size_List'].apply(lambda x: x[1])
        
        def calc_avg_size(row):
            mi, ma = row['QuyMoCongTyMin_clean'], row['QuyMoCongTyMax_clean']
            if pd.isna(mi): return np.nan
            if pd.isna(ma): return mi
            return (mi + ma) / 2
        
        df['QuyMoCongTyTB_clean'] = df.apply(calc_avg_size, axis=1)
        
        size_bins = [0, 10, 100, 500, 1000, 5000, float('inf')]
        size_labels = ["D∆∞·ªõi 10 nh√¢n vi√™n", "10 - 100 nh√¢n vi√™n", "100 - 500 nh√¢n vi√™n", 
                       "500 - 1000 nh√¢n vi√™n", "1000 - 5000 nh√¢n vi√™n", "Tr√™n 5000 nh√¢n vi√™n"]
        df['PhanLoaiQuyMoCongTy'] = pd.cut(df['QuyMoCongTyTB_clean'], bins=size_bins, labels=size_labels, right=False)
        df['PhanLoaiQuyMoCongTy'] = df['PhanLoaiQuyMoCongTy'].astype(str).replace({'nan': 'Kh√¥ng x√°c ƒë·ªãnh', 'None': 'Kh√¥ng x√°c ƒë·ªãnh'})

        print("‚è≥ [4/7] ƒêi·ªÅn khuy·∫øt d·ªØ li·ªáu (Imputation)...")
        cols_sal = ['MucLuongMin', 'MucLuongMax']
        for col in cols_sal:
            if col in df.columns:
                df[col] = df[col].replace(0, np.nan)
                df[col] = df[col].fillna(
                    df.groupby(['CongViec_clean', 'CapBac_YeuCau'])[col].transform('mean')
                )
                df[col] = df[col].fillna(0)

        df['MucLuongTB'] = (df['MucLuongMin'] + df['MucLuongMax']) / 2
        df['KhoangLuong'] = df['MucLuongTB'].apply(self._get_salary_range_label)

        print("‚è≥ [5/7] T√°ch ƒë·ªãa ƒëi·ªÉm (Explode)...")
        df_final = self.clean_location_data(df)
        
        print("‚è≥ [6/7] T·∫°o JobHash & Ch·ªçn c·ªôt Output...")
        
        # --- [C·∫¨P NH·∫¨T LOGIC HASH THEO Y√äU C·∫¶U] ---
        def _make_hash(row):
            link = str(row.get('LinkBaiTuyenDung', '')).strip().lower()
            
            # [S·ª¨A T·∫†I ƒê√ÇY]: D√πng ViTri_clean thay v√¨ Tinh_Thanh
            # ViTri_clean l√† gi√° tr·ªã unique sau khi explode (VD: d√≤ng 1 l√† HN, d√≤ng 2 l√† HCM)
            vitri = str(row.get('ViTri_clean', '')).strip().lower() 
            
            title = str(row.get('CongViec', '')).strip().lower()
            
            # T·∫°o key duy nh·∫•t: Link + ƒê·ªãa ƒëi·ªÉm c·ª• th·ªÉ + T√™n Job
            combined = f"{link}|{vitri}|{title}"
            return hashlib.md5(combined.encode('utf-8')).hexdigest()

        # √Åp d·ª•ng h√†m Hash
        df_final['JobHash'] = df_final.apply(_make_hash, axis=1)
        df_final['NgayXuLyDL'] = datetime.now()

        output_cols = [
            'JobID', 'JobHash', 'LinkBaiTuyenDung', 
            'CongTy', 'CongTy_clean', 
            'CongViec', 'CongViec_clean', 
            'CapBac', 'CapBac_YeuCau', 
            'ViTri', 'ViTri_clean', 'Tinh_Thanh', 'KhuVuc', 'Latitude', 'Longitude',
            'MucLuong', 'MucLuongMin', 'MucLuongMax', 'MucLuongTB', 'KhoangLuong',
            'MoTaCongViec', 'YeuCauUngVien',
            'YeuCauKinhNghiem', 'YeuCauKinhNghiemMin', 'YeuCauKinhNghiemMax', 'YeuCauKinhNghiemTB', 'PhanLoaiKinhNghiem',
            'HardSkills', 'SoftSkills',
            'LinhVuc', 'LinhVuc_clean',
            'HocVan', 'HocVan_clean',
            'HinhThucLamViec', 'HinhThucLamViec_clean', 'KieuLamViec_clean', # Map ƒë√∫ng t√™n c·ªôt
            'SoLuongTuyen', 'SoLuongTuyen_clean',
            'QuyMoCongTy', 'QuyMoCongTyMin_clean', 'QuyMoCongTyMax_clean', 'QuyMoCongTyTB_clean', 'PhanLoaiQuyMoCongTy',
            'HanNopHoSo', 'HanNopHoSo_clean',
            'Nguon', 'NgayCaoDuLieu', 'NgayXuLyDL'
        ]

        # Map t√™n c·ªôt (n·∫øu t√™n trong process_* kh√°c t√™n trong output)
        if 'KieuLamViec' in df_final.columns: df_final['KieuLamViec_clean'] = df_final['KieuLamViec']
        if 'HinhThucLamViec' in df_final.columns: df_final['HinhThucLamViec_clean'] = df_final['HinhThucLamViec']
        if 'YeuCauKiNangCung_clean' in df_final.columns: df_final['HardSkills'] = df_final['YeuCauKiNangCung_clean']
        if 'YeuCauKiNangMem_clean' in df_final.columns: df_final['SoftSkills'] = df_final['YeuCauKiNangMem_clean']

        # Fill c·ªôt thi·∫øu
        for col in output_cols:
            if col not in df_final.columns: df_final[col] = None
            
        df_ready = df_final[output_cols].copy()

        print("‚è≥ [7/7] L∆∞u v√†o Database (Procedure JSON Upsert)...")
        self.save_data_via_procedure(df_ready)
        return df_final
if __name__ == "__main__":
    pipeline = RecruitmentETL(DATABASE_URL)
    df = pipeline.run()
    