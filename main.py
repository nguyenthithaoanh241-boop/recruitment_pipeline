# main.py

import sys
import os
import random
# import time # <- KhÃ´ng cáº§n ná»¯a
# import glob # <- KhÃ´ng cáº§n ná»¯a
# import pandas as pd # <- KhÃ´ng cáº§n ná»¯a

# ThÃªm Ä‘Æ°á»ng dáº«n dá»± Ã¡n vÃ o sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# --- Import cÃ¡c thÃ nh pháº§n cá»§a pipeline ---
# from pipeline.config import DATASET_DIR, ARCHIVE_DIR # <- KhÃ´ng cáº§n á»Ÿ file nÃ y ná»¯a
from pipeline.db_setup import setup_database_tables
# from pipeline.loader import load_data_to_postgres # <- KhÃ´ng cÃ²n dÃ¹ng hÃ m nÃ y á»Ÿ Ä‘Ã¢y
from pipeline.transformer import transform_data # <- Giá»¯ láº¡i cho BÆ°á»›c 3

# --- Import cÃ¡c CLASS Scraper ---
# (Giáº£ sá»­ file CareerViet.py cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c sá»­a)
from scrapers.TopCV import TopCVScraper
from scrapers.Careerlink import CareerLinkScraper


def run_full_pipeline():
    """
    Cháº¡y toÃ n bá»™ pipeline ETL tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i.
    """
    print("ðŸš€ Báº®T Äáº¦U CHáº Y PIPELINE TUYá»‚N Dá»¤NG ðŸš€")
    # BÆ°á»›c 0: Thiáº¿t láº­p database (Giá»¯ nguyÃªn)
    print("\n----- BÆ¯á»šC 0: THIáº¾T Láº¬P DATABASE -----")
    setup_database_tables()
    
    # BÆ°á»›c 1: Crawl VÃ€ LOAD dá»¯ liá»‡u tá»« cÃ¡c nguá»“n
    print("\n----- BÆ¯á»šC 1: CRAWL & LOAD Dá»® LIá»†U -----")
    try:
        # 1. Khá»Ÿi táº¡o cÃ¡c "Ä‘á»‘i tÆ°á»£ng" scraper
        topcv_scraper = TopCVScraper()
        
        careerlink_hardware = CareerLinkScraper(
            category_name="PhanCungMang",
            base_url="https://www.careerlink.vn/viec-lam/cntt-phan-cung-mang/130"
        )
        
        careerlink_software = CareerLinkScraper(
            category_name="PhanMem",
            base_url="https://www.careerlink.vn/viec-lam/cntt-phan-mem/19"
        )
        
       
        # careerviet_software = CareerVietScraper(
        #     category_name="PhanMem",
        #     base_url="https://careerviet.vn/viec-lam/cntt-phan-mem-c1-vi.html"
        # )
        # careerviet_hardware = CareerVietScraper(
        #     category_name="PhanCung",
        #     base_url="https://careerviet.vn/viec-lam/cntt-phan-cung-mang-c63-vi.html"
        # )

        # 2. Táº¡o danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng scraper cáº§n cháº¡y
        scrapers_to_choose_from = [
            topcv_scraper,
            careerlink_hardware,
            careerlink_software,
            #careerviet_hardware,
            #careerviet_software
        ]

        # 3. Chá»n ngáº«u nhiÃªn má»™t Ä‘á»‘i tÆ°á»£ng scraper tá»« danh sÃ¡ch
        chosen_scraper = random.choice(scrapers_to_choose_from)

        # In ra Ä‘á»ƒ biáº¿t scraper nÃ o Ä‘Æ°á»£c chá»n
        scraper_name = chosen_scraper.__class__.__name__
        category = getattr(chosen_scraper, 'category_name', 'Default') # Láº¥y category_name náº¿u cÃ³
        print(f"ðŸ¤– Láº§n nÃ y sáº½ cháº¡y ngáº«u nhiÃªn scraper: {scraper_name} (Category: {category})")
        
        # 4. Cháº¡y phÆ°Æ¡ng thá»©c .run() cá»§a Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ Ä‘Æ°á»£c chá»n
        # !!! QUAN TRá»ŒNG:
        # HÃ m .run() nÃ y bÃ¢y giá» Ä‘Ã£ bao gá»“m cáº£ viá»‡c cÃ o,
        # lÆ°u CSV, náº¡p vÃ o DB vÃ  xÃ³a file CSV.
        chosen_scraper.run() 
        
    except Exception as e:
        print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh cÃ o dá»¯ liá»‡u (Step 1): {e}")

    # BÆ°á»›c 3: Transform dá»¯ liá»‡u vÃ  náº¡p vÃ o Production
    print("\n----- BÆ¯á»šC 3: TRANSFORM Dá»® LIá»†U SANG PRODUCTION -----")
    # (BÆ°á»›c nÃ y sáº½ lÃ  bÆ°á»›c tiáº¿p theo chÃºng ta lÃ m)
    # transform_data()
    
    print("\nðŸŽ‰ PIPELINE HOÃ€N Táº¤T! ðŸŽ‰")

if __name__ == "__main__":
    run_full_pipeline()