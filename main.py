# main.py

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# --- Import cÃ¡c thÃ nh pháº§n cá»§a pipeline ---
from pipeline.transformer import transform_data 
from pipeline.config import DATASET_DIR, DB_TYPE 

# --- Import cÃ¡c CLASS Scraper ---
from scrapers.TopCV import TopCVScraper
from scrapers.Careerlink import CareerLinkScraper

# --- Import hÃ m LOADER má»›i ---
from pipeline.loader import load_csv_to_staging_and_cleanup

# ... (HÃ m run_scrapers(scrapers) giá»¯ nguyÃªn, khÃ´ng cáº§n sá»­a) ...
def run_scrapers(scrapers: list) -> list:
    all_saved_files = []
    for scraper in scrapers:
        try:
            scraper_name = scraper.__class__.__name__
            category = getattr(scraper, 'category_name', 'Default')
            print(f"\nğŸ¤– Báº¯t Ä‘áº§u cháº¡y: {scraper_name} (Category: {category})")
            saved_file = scraper.run() 
            if saved_file:
                print(f"-> ÄÃ£ lÆ°u file: {saved_file}")
                all_saved_files.append(saved_file)
            else:
                print(f"-> {scraper_name} khÃ´ng tráº£ vá» file nÃ o.")
        except Exception as e:
            print(f"âŒ Lá»—i nghiÃªm trá»ng khi cháº¡y {scraper.__class__.__name__}: {e}")
    return all_saved_files


def run_full_pipeline():
    print("ğŸš€ Báº®T Äáº¦U CHáº Y PIPELINE TUYá»‚N Dá»¤NG ğŸš€")
    
    # --- BÆ¯á»šC 1: CRAWL (Giá»¯ nguyÃªn) ---
    print("\n----- BÆ¯á»šC 1: CRAWL Dá»® LIá»†U (LÆ¯U RA CSV) -----")
    scrapers_to_run = [
        TopCVScraper(),
        CareerLinkScraper(
            category_name="PhanCungMang",
            base_url="https://www.careerlink.vn/viec-lam/cntt-phan-cung-mang/130"
        ),
        CareerLinkScraper(
            category_name="PhanMem",
            base_url="https://www.careerlink.vn/viec-lam/cntt-phan-mem/19"
        ),
    ]
    saved_files = run_scrapers(scrapers_to_run)
    
    if not saved_files:
        print("\nHoÃ n táº¥t: KhÃ´ng cÃ³ file nÃ o Ä‘Æ°á»£c cÃ o. Dá»«ng pipeline.")
        return
    print(f"\n-> HoÃ n táº¥t BÆ¯á»šC 1: {len(saved_files)} file Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {DATASET_DIR}.")

    # --- BÆ¯á»šC 2: LOAD Dá»® LIá»†U (Cáº­p nháº­t) ---
    print("\n----- BÆ¯á»šC 2: LOAD Dá»® LIá»†U Tá»ª CSV VÃ€O DATABASE -----")

    # ğŸ‘‡ Tá»° Äá»˜NG CHá»ŒN SCHEMA Dá»°A TRÃŠN Cáº¤U HÃŒNH
    target_schema = None
    if DB_TYPE == 'sqlserver':
        target_schema = 'dbo'
    elif DB_TYPE == 'postgresql':
        target_schema = 'public'
    else:
        print(f"âŒ Lá»–I: KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c DB_TYPE '{DB_TYPE}' Ä‘á»ƒ chá»n schema.")
        print("Dá»«ng pipeline.")
        return # Dá»«ng láº¡i náº¿u khÃ´ng biáº¿t náº¡p vÃ o Ä‘Ã¢u

    print(f"-> Cháº¿ Ä‘á»™: {DB_TYPE}. Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c náº¡p vÃ o schema: '{target_schema}'")

    for file_name in saved_files:
        full_file_path = os.path.join(DATASET_DIR, file_name)
        
        print("-" * 20)
        load_csv_to_staging_and_cleanup(
            file_path=full_file_path,
            schema=target_schema,       
            table_name='raw_jobs_ta'    
        )
    
    print("\n-> HoÃ n táº¥t BÆ¯á»šC 2: Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c náº¡p vÃ  file CSV Ä‘Ã£ Ä‘Æ°á»£c dá»n dáº¹p.")

    # --- BÆ¯á»šC 3: TRANSFORM (Giá»¯ nguyÃªn) ---
    print("\n----- BÆ¯á»šC 3: TRANSFORM Dá»® LIá»†U SANG PRODUCTION -----")
    # transform_data()
    
    print("\nğŸ‰ PIPELINE HOÃ€N Táº¤T! ğŸ‰")

if __name__ == "__main__":
    run_full_pipeline()